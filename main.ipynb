{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:10:37.768816248Z",
     "start_time": "2023-10-31T16:10:37.759797621Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:10:38.240816560Z",
     "start_time": "2023-10-31T16:10:38.229635960Z"
    }
   },
   "id": "122a3f1fdf858106"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "filenames=os.listdir(\"train\")\n",
    "\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:10:38.945141665Z",
     "start_time": "2023-10-31T16:10:38.911672953Z"
    }
   },
   "id": "d731340118bcf8e5"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "            filename  category\n0       dog.3167.jpg         1\n1       cat.4508.jpg         0\n2      cat.11018.jpg         0\n3       cat.8644.jpg         0\n4      dog.11397.jpg         1\n...              ...       ...\n24995   dog.5408.jpg         1\n24996   dog.5861.jpg         1\n24997   dog.4655.jpg         1\n24998   dog.6967.jpg         1\n24999   cat.5726.jpg         0\n\n[25000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dog.3167.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cat.4508.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cat.11018.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cat.8644.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dog.11397.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>dog.5408.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>dog.5861.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>dog.4655.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>dog.6967.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>cat.5726.jpg</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:10:40.504943742Z",
     "start_time": "2023-10-31T16:10:40.481311065Z"
    }
   },
   "id": "3c0479fdf4180c30"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_img' from 'PIL.Image' (/home/ravshanjon/miniconda3/envs/praktikum/lib/python3.11/site-packages/PIL/Image.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[116], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mImage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_img\n\u001B[1;32m     10\u001B[0m model\u001B[38;5;241m=\u001B[39mSequential()\n\u001B[1;32m     12\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Conv2D(\u001B[38;5;241m32\u001B[39m,(\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m3\u001B[39m),activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m,input_shape\u001B[38;5;241m=\u001B[39m(Image_Width,Image_Height,Image_Channels)))\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'load_img' from 'PIL.Image' (/home/ravshanjon/miniconda3/envs/praktikum/lib/python3.11/site-packages/PIL/Image.py)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D, \\\n",
    "    Dropout,Flatten,Dense,Activation, \\\n",
    "    BatchNormalization\n",
    "# from keras.preprocessing.image import load_img\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:22:56.750239030Z",
     "start_time": "2023-10-31T16:22:56.694290832Z"
    }
   },
   "id": "65781662da8ddc52"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 126, 126, 32)      128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 63, 63, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 61, 61, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 30, 30, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 28, 28, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 14, 14, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               12845568  \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12942786 (49.37 MB)\n",
      "Trainable params: 12941314 (49.37 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:22:13.080753389Z",
     "start_time": "2023-10-31T16:22:13.020617376Z"
    }
   },
   "id": "2aa99b101889256e"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:22:13.214096460Z",
     "start_time": "2023-10-31T16:22:13.208777644Z"
    }
   },
   "id": "be52da4599fef16c"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
    "                                        random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:22:14.285466414Z",
     "start_time": "2023-10-31T16:22:14.250351279Z"
    }
   },
   "id": "23b596efbffbea52"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "            filename category\n0       dog.3167.jpg      dog\n1       cat.4508.jpg      cat\n2      cat.11018.jpg      cat\n3       cat.8644.jpg      cat\n4      dog.11397.jpg      dog\n...              ...      ...\n24995   dog.5408.jpg      dog\n24996   dog.5861.jpg      dog\n24997   dog.4655.jpg      dog\n24998   dog.6967.jpg      dog\n24999   cat.5726.jpg      cat\n\n[25000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dog.3167.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cat.4508.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cat.11018.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cat.8644.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dog.11397.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>dog.5408.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>dog.5861.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>dog.4655.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>dog.6967.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>cat.5726.jpg</td>\n      <td>cat</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:22:15.147506740Z",
     "start_time": "2023-10-31T16:22:15.136567283Z"
    }
   },
   "id": "bd137e606bcc3c72"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravshanjon/miniconda3/envs/praktikum/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 20000 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1\n",
    "                                   )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    \"train/\",x_col='filename',y_col='category',\n",
    "                                                    target_size=Image_Size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,\n",
    "    \"train/\",\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                  rescale=1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                   \"test/\",x_col='filename',y_col='category',\n",
    "                                                   target_size=Image_Size,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:22:16.430679111Z",
     "start_time": "2023-10-31T16:22:16.156774976Z"
    }
   },
   "id": "784e4c4f4ee30f00"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40140/1429405031.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[115], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m\n\u001B[0;32m----> 2\u001B[0m history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit_generator(\n\u001B[1;32m      3\u001B[0m     train_generator,\n\u001B[1;32m      4\u001B[0m     epochs\u001B[38;5;241m=\u001B[39mepochs,\n\u001B[1;32m      5\u001B[0m     validation_data\u001B[38;5;241m=\u001B[39mvalidation_generator,\n\u001B[1;32m      6\u001B[0m     validation_steps\u001B[38;5;241m=\u001B[39mtotal_validate\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39mbatch_size,\n\u001B[1;32m      7\u001B[0m     steps_per_epoch\u001B[38;5;241m=\u001B[39mtotal_train\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39mbatch_size,\n\u001B[1;32m      8\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks\n\u001B[1;32m      9\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/praktikum/lib/python3.11/site-packages/keras/src/engine/training.py:2889\u001B[0m, in \u001B[0;36mModel.fit_generator\u001B[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[1;32m   2877\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001B[39;00m\n\u001B[1;32m   2878\u001B[0m \n\u001B[1;32m   2879\u001B[0m \u001B[38;5;124;03mDEPRECATED:\u001B[39;00m\n\u001B[1;32m   2880\u001B[0m \u001B[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001B[39;00m\n\u001B[1;32m   2881\u001B[0m \u001B[38;5;124;03m  use this endpoint.\u001B[39;00m\n\u001B[1;32m   2882\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2883\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   2884\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`Model.fit_generator` is deprecated and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2885\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be removed in a future version. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2886\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease use `Model.fit`, which supports generators.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2887\u001B[0m     stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   2888\u001B[0m )\n\u001B[0;32m-> 2889\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m   2890\u001B[0m     generator,\n\u001B[1;32m   2891\u001B[0m     steps_per_epoch\u001B[38;5;241m=\u001B[39msteps_per_epoch,\n\u001B[1;32m   2892\u001B[0m     epochs\u001B[38;5;241m=\u001B[39mepochs,\n\u001B[1;32m   2893\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   2894\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[1;32m   2895\u001B[0m     validation_data\u001B[38;5;241m=\u001B[39mvalidation_data,\n\u001B[1;32m   2896\u001B[0m     validation_steps\u001B[38;5;241m=\u001B[39mvalidation_steps,\n\u001B[1;32m   2897\u001B[0m     validation_freq\u001B[38;5;241m=\u001B[39mvalidation_freq,\n\u001B[1;32m   2898\u001B[0m     class_weight\u001B[38;5;241m=\u001B[39mclass_weight,\n\u001B[1;32m   2899\u001B[0m     max_queue_size\u001B[38;5;241m=\u001B[39mmax_queue_size,\n\u001B[1;32m   2900\u001B[0m     workers\u001B[38;5;241m=\u001B[39mworkers,\n\u001B[1;32m   2901\u001B[0m     use_multiprocessing\u001B[38;5;241m=\u001B[39muse_multiprocessing,\n\u001B[1;32m   2902\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39mshuffle,\n\u001B[1;32m   2903\u001B[0m     initial_epoch\u001B[38;5;241m=\u001B[39minitial_epoch,\n\u001B[1;32m   2904\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/praktikum/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/praktikum/lib/python3.11/site-packages/keras/src/utils/image_utils.py:414\u001B[0m, in \u001B[0;36mload_img\u001B[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001B[0m\n\u001B[1;32m    412\u001B[0m     color_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrayscale\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pil_image \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m    415\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not import PIL.Image. The use of `load_img` requires PIL.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    416\u001B[0m     )\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, io\u001B[38;5;241m.\u001B[39mBytesIO):\n\u001B[1;32m    418\u001B[0m     img \u001B[38;5;241m=\u001B[39m pil_image\u001B[38;5;241m.\u001B[39mopen(path)\n",
      "\u001B[0;31mImportError\u001B[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T16:22:18.595010415Z",
     "start_time": "2023-10-31T16:22:18.542498735Z"
    }
   },
   "id": "1ad8f9eed4742b3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7052fd3689f9d551"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
